{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# add header names\n",
    "headers =  ['age', 'sex','chest_pain','resting_blood_pressure',  \n",
    "        'serum_cholestoral', 'fasting_blood_sugar', 'resting_ecg_results',\n",
    "        'max_heart_rate_achieved', 'exercise_induced_angina', 'oldpeak',\"slope of the peak\",\n",
    "        'num_of_major_vessels','thal', 'heart_disease']\n",
    "\n",
    "heart_df = pd.read_csv('/home/raffaele/Documents/ml-project/datasets/heart.dat', sep=' ', names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set is (216, 13)\n",
      "Shape of test set is (54, 13)\n",
      "Shape of train label is (216, 1)\n",
      "Shape of test labels is (54, 1)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#convert imput to numpy arrays\n",
    "X = heart_df.drop(columns=['heart_disease'])\n",
    "\n",
    "#replace target class with 0 and 1 \n",
    "#1 means \"have heart disease\" and 0 means \"do not have heart disease\"\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(1, 0)\n",
    "heart_df['heart_disease'] = heart_df['heart_disease'].replace(2, 1)\n",
    "\n",
    "y_label = heart_df['heart_disease'].values.reshape(X.shape[0], 1)\n",
    "\n",
    "#split data into train and test set\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_label, test_size=0.2, random_state=2)\n",
    "\n",
    "#standardize the dataset\n",
    "sc = StandardScaler()\n",
    "sc.fit(Xtrain)\n",
    "Xtrain = sc.transform(Xtrain)\n",
    "Xtest = sc.transform(Xtest)\n",
    "\n",
    "# Xtrain = Xtrain.reshape(Xtrain.shape[0], 1, 13)\n",
    "# Xtest = Xtest.reshape(Xtest.shape[0], 1, 13)\n",
    "# ytrain = ytrain.reshape(ytrain.shape[0], 1, 1)\n",
    "# ytest = ytest.reshape(ytest.shape[0], 1, 1)\n",
    "\n",
    "print(f\"Shape of train set is {Xtrain.shape}\")\n",
    "print(f\"Shape of test set is {Xtest.shape}\")\n",
    "print(f\"Shape of train label is {ytrain.shape}\")\n",
    "print(f\"Shape of test labels is {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            \n",
    "            if (output.shape == (1,1)):\n",
    "                output = output[0]\n",
    "                \n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                output = output.reshape(1, output.shape[0])\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples\n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100   error=0.201449\n",
      "epoch 2/100   error=0.144890\n",
      "epoch 3/100   error=0.118992\n",
      "epoch 4/100   error=0.107372\n",
      "epoch 5/100   error=0.101165\n",
      "epoch 6/100   error=0.097251\n",
      "epoch 7/100   error=0.094434\n",
      "epoch 8/100   error=0.092222\n",
      "epoch 9/100   error=0.090407\n",
      "epoch 10/100   error=0.088893\n",
      "epoch 11/100   error=0.087616\n",
      "epoch 12/100   error=0.086531\n",
      "epoch 13/100   error=0.085597\n",
      "epoch 14/100   error=0.084784\n",
      "epoch 15/100   error=0.084067\n",
      "epoch 16/100   error=0.083426\n",
      "epoch 17/100   error=0.082845\n",
      "epoch 18/100   error=0.082313\n",
      "epoch 19/100   error=0.081820\n",
      "epoch 20/100   error=0.081357\n",
      "epoch 21/100   error=0.080917\n",
      "epoch 22/100   error=0.080496\n",
      "epoch 23/100   error=0.080089\n",
      "epoch 24/100   error=0.079691\n",
      "epoch 25/100   error=0.079299\n",
      "epoch 26/100   error=0.078910\n",
      "epoch 27/100   error=0.078521\n",
      "epoch 28/100   error=0.078131\n",
      "epoch 29/100   error=0.077737\n",
      "epoch 30/100   error=0.077338\n",
      "epoch 31/100   error=0.076931\n",
      "epoch 32/100   error=0.076517\n",
      "epoch 33/100   error=0.076094\n",
      "epoch 34/100   error=0.075661\n",
      "epoch 35/100   error=0.075219\n",
      "epoch 36/100   error=0.074766\n",
      "epoch 37/100   error=0.074304\n",
      "epoch 38/100   error=0.073831\n",
      "epoch 39/100   error=0.073349\n",
      "epoch 40/100   error=0.072858\n",
      "epoch 41/100   error=0.072359\n",
      "epoch 42/100   error=0.071853\n",
      "epoch 43/100   error=0.071340\n",
      "epoch 44/100   error=0.070823\n",
      "epoch 45/100   error=0.070303\n",
      "epoch 46/100   error=0.069781\n",
      "epoch 47/100   error=0.069258\n",
      "epoch 48/100   error=0.068736\n",
      "epoch 49/100   error=0.068216\n",
      "epoch 50/100   error=0.067700\n",
      "epoch 51/100   error=0.067188\n",
      "epoch 52/100   error=0.066682\n",
      "epoch 53/100   error=0.066181\n",
      "epoch 54/100   error=0.065687\n",
      "epoch 55/100   error=0.065201\n",
      "epoch 56/100   error=0.064722\n",
      "epoch 57/100   error=0.064252\n",
      "epoch 58/100   error=0.063790\n",
      "epoch 59/100   error=0.063338\n",
      "epoch 60/100   error=0.062894\n",
      "epoch 61/100   error=0.062460\n",
      "epoch 62/100   error=0.062036\n",
      "epoch 63/100   error=0.061621\n",
      "epoch 64/100   error=0.061215\n",
      "epoch 65/100   error=0.060820\n",
      "epoch 66/100   error=0.060433\n",
      "epoch 67/100   error=0.060057\n",
      "epoch 68/100   error=0.059689\n",
      "epoch 69/100   error=0.059331\n",
      "epoch 70/100   error=0.058981\n",
      "epoch 71/100   error=0.058640\n",
      "epoch 72/100   error=0.058308\n",
      "epoch 73/100   error=0.057984\n",
      "epoch 74/100   error=0.057667\n",
      "epoch 75/100   error=0.057358\n",
      "epoch 76/100   error=0.057056\n",
      "epoch 77/100   error=0.056761\n",
      "epoch 78/100   error=0.056472\n",
      "epoch 79/100   error=0.056190\n",
      "epoch 80/100   error=0.055913\n",
      "epoch 81/100   error=0.055642\n",
      "epoch 82/100   error=0.055376\n",
      "epoch 83/100   error=0.055115\n",
      "epoch 84/100   error=0.054858\n",
      "epoch 85/100   error=0.054606\n",
      "epoch 86/100   error=0.054358\n",
      "epoch 87/100   error=0.054114\n",
      "epoch 88/100   error=0.053873\n",
      "epoch 89/100   error=0.053636\n",
      "epoch 90/100   error=0.053401\n",
      "epoch 91/100   error=0.053170\n",
      "epoch 92/100   error=0.052942\n",
      "epoch 93/100   error=0.052716\n",
      "epoch 94/100   error=0.052493\n",
      "epoch 95/100   error=0.052273\n",
      "epoch 96/100   error=0.052055\n",
      "epoch 97/100   error=0.051840\n",
      "epoch 98/100   error=0.051628\n",
      "epoch 99/100   error=0.051418\n",
      "epoch 100/100   error=0.051212\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from layers import LayerDense,ActivationLayer\n",
    "from activations import tanh, tanh_prime, sigmoid, sigmoid_prime\n",
    "from losses import mse, mse_prime\n",
    "\n",
    "# network\n",
    "net = Network()\n",
    "net.add(LayerDense(13, 5))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "net.add(LayerDense(5, 1))\n",
    "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
    "# train\n",
    "net.use(mse, mse_prime)\n",
    "net.fit(Xtrain, ytrain, epochs=100, learning_rate=0.1)\n",
    "\n",
    "# test\n",
    "out = net.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for i in out:\n",
    "    i = np.round(i)\n",
    "    res.append(i)\n",
    "    \n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(res == ytrain) / len(ytrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
